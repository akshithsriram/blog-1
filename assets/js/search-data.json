{
  
    
        "post0": {
            "title": "Distinguish Your Own Digits (DYOD)",
            "content": "A classifier that distinguishes between the number 3 and number 8. . %load_ext autoreload %autoreload 2 . %matplotlib inline import numpy as np import matplotlib.pyplot as plt import pandas as pd . From the command line run pip install mnist. This is a library that will help you bring down the mnist dataset. If you run this from a notebook, you need to put !pip install mnist in a cell by itself. . !pip install mnist . Requirement already satisfied: mnist in c: users lenovo anaconda3 lib site-packages (0.2.2) Requirement already satisfied: numpy in c: users lenovo anaconda3 lib site-packages (from mnist) (1.18.1) . Preparing the Data . import mnist . train_images = mnist.train_images() train_labels = mnist.train_labels() . train_images.shape, train_labels.shape . ((60000, 28, 28), (60000,)) . test_images = mnist.test_images() test_labels = mnist.test_labels() test_labels[0:2] . array([7, 2], dtype=uint8) . test_images.shape, test_labels.shape . ((10000, 28, 28), (10000,)) . image_index = 7776 # You may select anything up to 60,000 print(train_labels[image_index]) plt.imshow(train_images[image_index], cmap=&#39;Greys&#39;) #plt.imshow(test_images[image_index], cmap=&#39;Greys&#39;) . 2 . &lt;matplotlib.image.AxesImage at 0x13a295ac448&gt; . Filter data to get 3 and 8 out . train_filter = np.where((train_labels == 3 ) | (train_labels == 8)) test_filter = np.where((test_labels == 3) | (test_labels == 8)) X_train, y_train = train_images[train_filter], train_labels[train_filter] X_test, y_test = test_images[test_filter], test_labels[test_filter] . We normalize the pizel values in the 0 to 1 range . X_train = X_train/255. X_test = X_test/255. . And setup the labels as 1 (when the digit is 3) and 0 (when the digit is 8) . y_train = 1*(y_train==3) y_test = 1*(y_test==3) . X_train.shape, X_test.shape . ((11982, 28, 28), (1984, 28, 28)) . We reshape the data to flatten the image pixels into a set of features or co-variates: . X_train = X_train.reshape(X_train.shape[0], -1) X_test = X_test.reshape(X_test.shape[0], -1) X_train.shape, X_test.shape . ((11982, 784), (1984, 784)) . Importing appropriate functions from &#39;Kudzu&#39; . from kudzu_a.layer import Sigmoid from kudzu_a.layer import Relu from kudzu_a.layer import Affine, Sigmoid from kudzu_a.model import Model from kudzu_a.train import Learner from kudzu_a.optim import GD from kudzu_a.data import Data, Dataloader, Sampler from kudzu_a.callbacks import AccCallback from kudzu_a.callbacks import ClfCallback from kudzu_a.loss import MSE . #creating a Config class, to store important parameters. class Config: pass config = Config() config.lr = 0.001 config.num_epochs = 251 config.bs = 50 . #initialising variables data = Data(X_train, y_train.reshape(-1,1)) sampler = Sampler(data, config.bs, shuffle=True) dl = Dataloader(data, sampler) opt = GD(config.lr) loss = MSE() . training_xdata = X_train testing_xdata = X_test training_ydata = y_train.reshape(-1,1) testing_ydata = y_test.reshape(-1,1) . Training the model . # layers for the Neural Network layers = [Affine(&quot;first&quot;, 784, 100), Relu(&quot;first&quot;), Affine(&quot;second&quot;, 100, 100), Relu(&quot;second&quot;), Affine(&quot;third&quot;, 100, 2), Affine(&quot;final&quot;, 2, 1), Sigmoid(&quot;final&quot;)] model_nn = Model(layers) # layers for the Logistic Regression layers_lr = [Affine(&quot;logits&quot;, 784, 1), Sigmoid(&quot;sigmoid&quot;)] model_lr = Model(layers_lr) . learner_nn = Learner(loss, model_nn, opt, config.num_epochs) acc_nn = ClfCallback(learner_nn, config.bs, training_xdata , testing_xdata, training_ydata, testing_ydata) learner_nn.set_callbacks([acc_nn]) learner_lr = Learner(loss, model_lr, opt, config.num_epochs) acc_lr = ClfCallback(learner_lr, config.bs, training_xdata , testing_xdata, training_ydata, testing_ydata) learner_lr.set_callbacks([acc_lr]) learner_nn.train_loop(dl) . Epoch 0, Loss 0.0109 Training Accuracy: 0.9892, Testing Accuracy: 0.9839 Epoch 10, Loss 0.0107 Training Accuracy: 0.9895, Testing Accuracy: 0.9839 Epoch 20, Loss 0.0105 Training Accuracy: 0.9898, Testing Accuracy: 0.9839 Epoch 30, Loss 0.0103 Training Accuracy: 0.9900, Testing Accuracy: 0.9839 Epoch 40, Loss 0.0101 Training Accuracy: 0.9903, Testing Accuracy: 0.9839 Epoch 50, Loss 0.01 Training Accuracy: 0.9904, Testing Accuracy: 0.9839 Epoch 60, Loss 0.0098 Training Accuracy: 0.9906, Testing Accuracy: 0.9849 Epoch 70, Loss 0.0096 Training Accuracy: 0.9906, Testing Accuracy: 0.9854 Epoch 80, Loss 0.0095 Training Accuracy: 0.9908, Testing Accuracy: 0.9859 Epoch 90, Loss 0.0093 Training Accuracy: 0.9910, Testing Accuracy: 0.9864 Epoch 100, Loss 0.0091 Training Accuracy: 0.9916, Testing Accuracy: 0.9869 Epoch 110, Loss 0.009 Training Accuracy: 0.9916, Testing Accuracy: 0.9869 Epoch 120, Loss 0.0088 Training Accuracy: 0.9917, Testing Accuracy: 0.9869 Epoch 130, Loss 0.0087 Training Accuracy: 0.9918, Testing Accuracy: 0.9869 Epoch 140, Loss 0.0085 Training Accuracy: 0.9919, Testing Accuracy: 0.9869 Epoch 150, Loss 0.0084 Training Accuracy: 0.9921, Testing Accuracy: 0.9874 Epoch 160, Loss 0.0082 Training Accuracy: 0.9923, Testing Accuracy: 0.9874 Epoch 170, Loss 0.0081 Training Accuracy: 0.9927, Testing Accuracy: 0.9874 Epoch 180, Loss 0.008 Training Accuracy: 0.9928, Testing Accuracy: 0.9874 Epoch 190, Loss 0.0078 Training Accuracy: 0.9929, Testing Accuracy: 0.9874 Epoch 200, Loss 0.0077 Training Accuracy: 0.9930, Testing Accuracy: 0.9874 Epoch 210, Loss 0.0076 Training Accuracy: 0.9933, Testing Accuracy: 0.9874 Epoch 220, Loss 0.0074 Training Accuracy: 0.9934, Testing Accuracy: 0.9874 Epoch 230, Loss 0.0073 Training Accuracy: 0.9937, Testing Accuracy: 0.9874 Epoch 240, Loss 0.0072 Training Accuracy: 0.9939, Testing Accuracy: 0.9874 Epoch 250, Loss 0.0071 Training Accuracy: 0.9939, Testing Accuracy: 0.9884 . 0.0039530857713519045 . learner_lr.train_loop(dl) . Epoch 0, Loss 0.2716 Training Accuracy: 0.5471, Testing Accuracy: 0.5776 Epoch 10, Loss 0.1089 Training Accuracy: 0.8974, Testing Accuracy: 0.9083 Epoch 20, Loss 0.0824 Training Accuracy: 0.9236, Testing Accuracy: 0.9315 Epoch 30, Loss 0.0704 Training Accuracy: 0.9343, Testing Accuracy: 0.9441 Epoch 40, Loss 0.0632 Training Accuracy: 0.9403, Testing Accuracy: 0.9476 Epoch 50, Loss 0.0583 Training Accuracy: 0.9437, Testing Accuracy: 0.9506 Epoch 60, Loss 0.0548 Training Accuracy: 0.9463, Testing Accuracy: 0.9546 Epoch 70, Loss 0.052 Training Accuracy: 0.9491, Testing Accuracy: 0.9567 Epoch 80, Loss 0.0499 Training Accuracy: 0.9507, Testing Accuracy: 0.9582 Epoch 90, Loss 0.0481 Training Accuracy: 0.9522, Testing Accuracy: 0.9607 Epoch 100, Loss 0.0466 Training Accuracy: 0.9529, Testing Accuracy: 0.9612 Epoch 110, Loss 0.0453 Training Accuracy: 0.9542, Testing Accuracy: 0.9627 Epoch 120, Loss 0.0442 Training Accuracy: 0.9552, Testing Accuracy: 0.9632 Epoch 130, Loss 0.0432 Training Accuracy: 0.9557, Testing Accuracy: 0.9647 Epoch 140, Loss 0.0423 Training Accuracy: 0.9559, Testing Accuracy: 0.9652 Epoch 150, Loss 0.0415 Training Accuracy: 0.9565, Testing Accuracy: 0.9642 Epoch 160, Loss 0.0408 Training Accuracy: 0.9569, Testing Accuracy: 0.9647 Epoch 170, Loss 0.0402 Training Accuracy: 0.9578, Testing Accuracy: 0.9647 Epoch 180, Loss 0.0396 Training Accuracy: 0.9580, Testing Accuracy: 0.9647 Epoch 190, Loss 0.0391 Training Accuracy: 0.9585, Testing Accuracy: 0.9657 Epoch 200, Loss 0.0386 Training Accuracy: 0.9589, Testing Accuracy: 0.9667 Epoch 210, Loss 0.0381 Training Accuracy: 0.9591, Testing Accuracy: 0.9657 Epoch 220, Loss 0.0377 Training Accuracy: 0.9594, Testing Accuracy: 0.9662 Epoch 230, Loss 0.0373 Training Accuracy: 0.9598, Testing Accuracy: 0.9662 Epoch 240, Loss 0.0369 Training Accuracy: 0.9599, Testing Accuracy: 0.9657 Epoch 250, Loss 0.0366 Training Accuracy: 0.9603, Testing Accuracy: 0.9662 . 0.013202055573088477 . plt.figure(figsize=(15,10)) # Neural Network plots plt.plot(acc_nn.accuracies, &#39;r-&#39;, label = &quot;Training Accuracies - NN&quot;) plt.plot(acc_nn.test_accuracies, &#39;g-&#39;, label = &quot;Testing Accuracies - NN&quot;) # Logistic Regression plots plt.plot(acc_lr.accuracies, &#39;k-&#39;, label = &quot;Training Accuracies - LR&quot;) plt.plot(acc_lr.test_accuracies, &#39;b-&#39;, label = &quot;Testing Accuracies - LR&quot;) plt.legend() . &lt;matplotlib.legend.Legend at 0x13a2fff2608&gt; . Plotting the outputs of this layer of the NN. . model_new = Model(layers[:-2]) plot_testing = model_new(testing_xdata) . Plotting the scatter plot of points and color coding by class . plt.figure(figsize=(8,7)) plt.scatter(plot_testing[:,0], plot_testing[:,1], alpha = 0.1, c = y_test.ravel()); plt.title(&#39;Outputs&#39;) . Text(0.5, 1.0, &#39;Outputs&#39;) . Probability contours . model_prob = Model(layers[-2:]) # Adjust the x and y ranges according to the above generated plot. x_range = np.linspace(-4, 1, 100) y_range = np.linspace(-6, 6, 100) x_grid, y_grid = np.meshgrid(x_range, y_range) # x_grid and y_grig are of size 100 X 100 # converting x_grid and y_grid to continuous arrays x_grid_flat = np.ravel(x_grid) y_grid_flat = np.ravel(y_grid) # The last layer of the current model takes two columns as input. Hence transpose of np.vstack() is required. X = np.vstack((x_grid_flat, y_grid_flat)).T # x_grid and y_grid are of size 100 x 100 probability_contour = model_prob(X).reshape(100,100) . plt.figure(figsize=(10,9)) plt.scatter(plot_testing[:,0], plot_testing[:,1], alpha = 0.1, c = y_test.ravel()) contours = plt.contour(x_grid,y_grid,probability_contour) plt.title(&#39;Probability Contours&#39;) plt.clabel(contours, inline = True ); .",
            "url": "https://ganeshtmvs.github.io/blog/2020/08/12/project-univ.ai.html",
            "relUrl": "/2020/08/12/project-univ.ai.html",
            "date": " • Aug 12, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "Covid-19 Dashboard: Daily updates",
            "content": "This version of the dashboard updates itself everyday with the latest information. . India . Last update: 11-Aug-20 . Confirmed cases: . 2328313 (+61252) . Confirmed deaths: . 46199 (+835) . Last Updated: 11:26:55.111405 .",
            "url": "https://ganeshtmvs.github.io/blog/2020/08/11/Daily-Covid-Updates.html",
            "relUrl": "/2020/08/11/Daily-Covid-Updates.html",
            "date": " • Aug 11, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "COVID-19 India Matplotlib Overview",
            "content": "India . Last update: 28th July, 2020 . Confirmed cases: . 1514800 (+49001) . Confirmed deaths: . 34121 (+770) . states Cases Deaths PCases PDeaths Cases (+) Deaths (+) Fatality Rate Maharashtra 391440 14164 383723 13882 7717 282 3.62 Tamil Nadu 227688 3659 220716 3571 6972 88 1.61 Delhi 132275 3881 131219 3853 1056 28 2.93 Andhra Pradesh 110297 1148 102349 1090 7948 58 1.04 Karnataka 107001 2064 101465 1962 5536 102 1.93 Uttar Pradesh 73951 1497 70493 1456 3458 41 2.02 West Bengal 62964 1449 60830 1411 2134 38 2.30 Gujarat 57982 2372 56874 2348 1108 24 4.09 Telangana 57142 480 55532 471 1610 9 0.84 Bihar 43591 269 41111 255 2480 14 0.62 Rajasthan 38636 644 37564 633 1072 11 1.67 Assam 34846 92 33475 90 1371 2 0.26 Haryana 32876 406 32127 397 749 9 1.23 Madhya Pradesh 29217 831 28589 821 628 10 2.84 Orissa 28107 189 26892 181 1215 8 0.67 Kerala 20895 68 19728 64 1167 4 0.33 Jammu and Kashmir 18879 333 18390 321 489 12 1.76 Punjab 14378 336 13769 318 609 18 2.34 Jharkhand 9563 94 8803 90 760 4 0.98 Goa 5287 36 5119 36 168 0 0.68 Tripura 4287 21 4066 17 221 4 0.49 Pondicherry 3013 47 2874 43 139 4 1.56 Himachal Pradesh 2330 13 2270 13 60 0 0.56 Manipur 2317 0 2286 0 31 0 0.00 Nagaland 1460 4 1385 5 75 0 0.27 Arunachal Pradesh 1330 3 1239 3 91 0 0.23 Chandigarh 934 14 910 14 24 0 1.50 Meghalaya 779 5 738 5 41 0 0.64 Sikkim 592 1 568 1 24 0 0.17 Mizoram 384 0 361 0 23 0 0.00 Andaman and Nicobar Islands 359 1 334 1 25 0 0.28 Daman and Diu 0 0 0 0 0 0 NaN Lakshadweep 0 0 0 0 0 0 NaN .",
            "url": "https://ganeshtmvs.github.io/blog/2020/08/11/Covid-updates-(-to-2020-07-28).html",
            "relUrl": "/2020/08/11/Covid-updates-(-to-2020-07-28).html",
            "date": " • Aug 11, 2020"
        }
        
    
  

  
  

  

  
  

  
  

  
  

  
  

  
  

  
      ,"page7": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://ganeshtmvs.github.io/blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}